# PROJECT-1. Анализ резюме из HeadHunter

## Оглавление  
[1. Описание проекта](README.md#1.-Описание-проекта)   
[2. Краткая информация о данных](README.md#2.-Краткая-информация-о-данных)  
[3. Этапы работы над проектом](README.md#3.-Этапы-работы-над-проектом)  
[4. Результаты](README.md#4.-Результаты)    
[5. Выводы](README.md#5.-Выводы) 

### 1. Описание проекта    
Дана база резюме с сайта поиска вакансий hh.ru. Компания HeadHunter хочет построить модель, которая бы автоматически определяла примерный уровень заработной платы, подходящей пользователю, исходя из информации, которую он указал о себе. Для дальшейшей работы и построения модели эти данные необходимо преобразовать, исследовать и очистить, что и выполнено в данном проекте.

***Составные части проекта:***

* [Project-1.CVAnalysisFromHH.ipynb](./Project-1.CVAnalysisFromHH.ipynb) - jupyter-ноутбук, содержащий основной код проекта
* [graphs](https://drive.google.com/drive/folders/1IBYR3ZBLJjBoPaGeqvnmytpgsu_tA4hs?usp=sharing) - графики, полученные в процессе анализа, в формате .html и загруженные на Google Диск

:arrow_up:[к оглавлению](README.md#Оглавление)


### 2. Краткая информация о данных
Исходными данными является база резюме в формате .csv, [загруженная на Google Диск](https://drive.google.com/file/d/1okl1YaTT3aUcUl20D1IKDuWFQhqysSVr/view?usp=drive_link)

Также в работе используется выгрузка курсов валют, [загруженная на Google Диск](https://drive.google.com/file/d/1tBQf-ZP-wssi8-BclM3rGORc6WJ4mg6-/view?usp=drive_link) которые встречаются в данных за период с 29.12.2017 по 05.12.2019


**Используемые библиотеки:**
* Python (3.9):
    * [numpy (1.24.2)](https://numpy.org)
    * [pandas (1.5.3)](https://pandas.pydata.org)
    * [matplotlib (3.7.1)](https://matplotlib.org)
    * [seaborn (0.12.2)](https://seaborn.pydata.org)
    * [plotly (5.14.1)](https://plotly.com)

:arrow_up:[к оглавлению](README.md#Оглавление)


### 3. Этапы работы над проектом  

***Установка проекта***

```
git clone https://github.com/nastyashandrokha/CVAnalysisFromHH
```

**Данный проект** состоит из четырёх частей:

***1. Исследование структуры данных.***

На данном этапе важно понять, как устроены признаки в данных и какие типы они имеют, чтобы произвести дальнейшие преобразования.

***2. Преобразование данных.***

Поскольку исходные данные очень «сырые»: признаки представлены в неудобном для анализа и очистки формате, на данном этапе выполняется их преобразование. Это необходимо для дальшейней визуальной оценки зависимостей в данных и грамотной работе с ними.

***3. Разведывательный анализ.***

Разведывательный анализ (EDA) предназначен для выявления связей между признаками, выявления закономерностей, определения распределений признаков, поиска аномалий и других дефектов данных.

***4. Очистка данных.***

В данных пристутствуют значения, которые являются некорректными или вовсе пропущены. На данном этапе проводится удаление дубликатов, заполнение пропусков и ликвидация выбросов.

:arrow_up:[к оглавлению](README.md#Оглавление)


### 4. Результаты:  
Результатом работы является преобразованный, очищенный от лишних данных, пропусков, выбросов и аномальных значений датасет, а также его полный анализ с графиками и комментариями. 

:arrow_up:[к оглавлению](README.md#Оглавление)


### 5. Выводы:  
Данный проект можно использовать для дальшейшей работы, а именно для построения модели автоматического определения примерного уровня заработной соискателей.

:arrow_up:[к оглавлению](README.md#Оглавление)

